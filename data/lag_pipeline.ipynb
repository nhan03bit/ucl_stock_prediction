{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bc994a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data normalized using MinMaxScaler\n",
      "X_train shape: (144, 28), X_test shape: (36, 28)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'r2_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 190\u001b[0m\n\u001b[1;32m    187\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m    189\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred)\n\u001b[0;32m--> 190\u001b[0m r2 \u001b[38;5;241m=\u001b[39m \u001b[43mr2_score\u001b[49m(y_test, y_pred)\n\u001b[1;32m    192\u001b[0m results[name] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSE\u001b[39m\u001b[38;5;124m'\u001b[39m: mse,\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR2\u001b[39m\u001b[38;5;124m'\u001b[39m: r2,\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Params\u001b[39m\u001b[38;5;124m'\u001b[39m: grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[1;32m    196\u001b[0m }\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r2_score' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Suppress warnings for cleaner notebook output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Wrapper for CatBoost to make it compatible with sklearn pipelines\n",
    "class CatBoostRegressorWrapper(CatBoostRegressor, BaseEstimator, RegressorMixin):\n",
    "    pass  # Inherits methods; BaseEstimator provides __sklearn_tags__\n",
    "# Define parameter grids\n",
    "param_grids = {\n",
    "    'LightGBM': {\n",
    "        'model__n_estimators': [100, 200, 300, 500, 1000],\n",
    "        'model__max_depth': [3, 5, 7, 9, 11, -1],\n",
    "        'model__learning_rate': [0.001, 0.01, 0.05, 0.1, 0.2],\n",
    "        'model__subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'model__colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'model__reg_alpha': [0, 0.001, 0.01, 0.1, 0.5, 1],\n",
    "        'model__reg_lambda': [0, 0.001, 0.01, 0.1, 0.5, 1],\n",
    "        'model__num_leaves': [31, 63, 127, 255]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model__n_estimators': [100, 200, 300, 500],\n",
    "        'model__max_depth': [3, 5, 7, 9, 11],\n",
    "        'model__learning_rate': [0.001, 0.01, 0.05, 0.1, 0.2],\n",
    "        'model__subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'model__colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'model__gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "        'model__reg_alpha': [0, 0.001, 0.01, 0.1],\n",
    "        'model__reg_lambda': [0.5, 1, 1.5, 2]\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'model__iterations': [100, 200, 300, 500],\n",
    "        'model__depth': [4, 6, 8, 10, 12],\n",
    "        'model__learning_rate': [0.001, 0.01, 0.05, 0.1, 0.2],\n",
    "        'model__l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "        'model__subsample': [0.6, 0.8, 1.0],\n",
    "        'model__colsample_bylevel': [0.6, 0.8, 1.0]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'model__n_estimators': [100, 200, 300, 500],\n",
    "        'model__learning_rate': [0.001, 0.01, 0.05, 0.1, 0.2],\n",
    "        'model__max_depth': [3, 5, 7, 9],\n",
    "        'model__subsample': [0.6, 0.8, 1.0],\n",
    "        'model__min_samples_split': [2, 5, 10],\n",
    "        'model__min_samples_leaf': [1, 2, 4],\n",
    "        'model__max_features': ['sqrt', 'log2', None]\n",
    "    },\n",
    "    'AdaBoost': {  # Limited grid for AdaBoost\n",
    "        'model__n_estimators': [50, 100, 200],\n",
    "        'model__learning_rate': [0.001, 0.01, 0.1, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Load real estate data\n",
    "data = pd.read_csv('preprocessed_real_estate_full.csv')  # Assuming original data file; adjust if needed\n",
    "\n",
    "# Rename columns based on the document (assuming standard PPD columns)\n",
    "\n",
    "# Convert date to datetime and sort\n",
    "data['date_of_transfer'] = pd.to_datetime(data['date_of_transfer'])\n",
    "data = data.sort_values('date_of_transfer')\n",
    "\n",
    "# Aggregate to daily mean price for time series forecasting\n",
    "daily_data = data.groupby('date_of_transfer')['price'].mean().reset_index()\n",
    "daily_data.rename(columns={'price': 'mean_real_estate_price'}, inplace=True)\n",
    "\n",
    "data = daily_data\n",
    "\n",
    "# Define target\n",
    "TARGET = 'mean_real_estate_price'\n",
    "\n",
    "# Create total rate for feature engineering (same as target since single output)\n",
    "data['total_rate'] = data[TARGET]\n",
    "\n",
    "# Create time-based features\n",
    "data['year'] = data['date_of_transfer'].dt.year\n",
    "data['month'] = data['date_of_transfer'].dt.month\n",
    "data['day'] = data['date_of_transfer'].dt.day\n",
    "data['dayofyear'] = data['date_of_transfer'].dt.dayofyear\n",
    "data['dayofweek'] = data['date_of_transfer'].dt.dayofweek\n",
    "data['quarter'] = data['date_of_transfer'].dt.quarter\n",
    "data['week'] = data['date_of_transfer'].dt.isocalendar().week\n",
    "data['is_weekend'] = (data['dayofweek'] >= 5).astype(int)\n",
    "\n",
    "# ============================================================\n",
    "# CREATE TIME SERIES FEATURES (Lagged Values + Rolling Stats)\n",
    "# ============================================================\n",
    "\n",
    "# Define lag periods (in days)\n",
    "lag_periods = [1, 2, 3, 5, 7, 14, 30, 60]\n",
    "\n",
    "# Create lagged features\n",
    "for lag in lag_periods:\n",
    "    data[f'total_lag_{lag}d'] = data['total_rate'].shift(lag)\n",
    "\n",
    "# Create rolling statistics\n",
    "rolling_windows = [5, 7, 14, 30, 60]\n",
    "for window in rolling_windows:\n",
    "    data[f'rolling_mean_{window}d'] = data['total_rate'].shift(1).rolling(window=window).mean()\n",
    "    data[f'rolling_std_{window}d'] = data['total_rate'].shift(1).rolling(window=window).std()\n",
    "\n",
    "# Create diff features\n",
    "data['rate_diff_1d'] = data['total_rate'].diff(1).shift(1)\n",
    "data['rate_diff_7d'] = data['total_rate'].diff(7).shift(1)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "\n",
    "# Original features (time-based)\n",
    "numerical_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "original_features = [col for col in numerical_cols if col not in [TARGET] \n",
    "                     and not col.startswith('total_') and not col.startswith('rolling_') \n",
    "                     and not col.startswith('rate_')]\n",
    "\n",
    "# Feature columns\n",
    "lag_features = [f'total_lag_{lag}d' for lag in lag_periods]\n",
    "rolling_features = [f'rolling_mean_{w}d' for w in rolling_windows] + [f'rolling_std_{w}d' for w in rolling_windows]\n",
    "diff_features = ['rate_diff_1d', 'rate_diff_7d']\n",
    "\n",
    "feature_cols = original_features + lag_features + rolling_features + diff_features\n",
    "\n",
    "X = data[feature_cols]\n",
    "y = data[TARGET]\n",
    "\n",
    "# Train-test split (time series)\n",
    "train_size = int(0.8 * len(data))\n",
    "X_train = X.iloc[:train_size]\n",
    "X_test = X.iloc[train_size:]\n",
    "y_train = y.iloc[:train_size]\n",
    "y_test = y.iloc[train_size:]\n",
    "\n",
    "# Normalize data with MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame to preserve column names\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=feature_cols, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=feature_cols, index=X_test.index)\n",
    "\n",
    "print('Data normalized using MinMaxScaler')\n",
    "print(f'X_train shape: {X_train.shape}, X_test shape: {X_test.shape}')\n",
    "\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'GradientBoosting': GradientBoostingRegressor(random_state=42),\n",
    "    'LightGBM': LGBMRegressor(random_state=42, verbose=-1),\n",
    "    'CatBoost': CatBoostRegressorWrapper(random_state=42, verbose=0),\n",
    "    'AdaBoost': AdaBoostRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Results dictionary\n",
    "results = {}\n",
    "\n",
    "# Train and evaluate each model with tuning\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grids[name],\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'MSE': mse,\n",
    "        'R2': r2,\n",
    "        'Best Params': grid_search.best_params_\n",
    "    }\n",
    "    print(f\"{name} MSE: {mse}\")\n",
    "    print(f\"{name} R2: {r2}\")\n",
    "    print(f\"{name} Best Params: {grid_search.best_params_}\")\n",
    "\n",
    "# ============================================================\n",
    "# MULTI-HORIZON FORECASTING WITH TUNED MODELS\n",
    "# ============================================================\n",
    "\n",
    "horizons = [1, 3, 5, 7, 14, 30]\n",
    "\n",
    "all_horizon_data = {}\n",
    "y_test_all_horizons = {}\n",
    "model_performances = {}\n",
    "\n",
    "for horizon in horizons:\n",
    "    print(f\"\\n=== Horizon: {horizon} days ===\")\n",
    "    X_train_h, X_test_h, y_train_h, y_test_h = prepare_horizon_data(X, y, horizon)\n",
    "    \n",
    "    horizon_results = {}\n",
    "    horizon_preds = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grids[name],\n",
    "            cv=5,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train_h, y_train_h)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        preds = best_model.predict(X_test_h)\n",
    "        \n",
    "        mse = mean_squared_error(y_test_h, preds)\n",
    "        \n",
    "        horizon_preds[name] = preds\n",
    "        horizon_results[name] = mse\n",
    "        \n",
    "        print(f\"{name} MSE for horizon {horizon}: {mse}\")\n",
    "    \n",
    "    all_horizon_data[horizon] = horizon_preds\n",
    "    y_test_all_horizons[horizon] = y_test_h\n",
    "    model_performances[horizon] = horizon_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf9b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZATION FUNCTIONS (Adapted for single target)\n",
    "# ============================================================\n",
    "\n",
    "def plot_combined_horizons_zoomed(all_horizon_data, y_test_data, zoom_factor=0.15):\n",
    "    horizons = sorted(all_horizon_data.keys())\n",
    "    \n",
    "    for horizon in horizons:\n",
    "        horizon_data = all_horizon_data[horizon]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(16, 8))\n",
    "        \n",
    "        model_colors = {\n",
    "            'GradientBoosting': '#1f77b4',\n",
    "            'LightGBM': '#ff7f0e',\n",
    "            'CatBoost': '#2ca02c',\n",
    "            'AdaBoost': '#d62728',\n",
    "            'XGBoost': '#9467bd'\n",
    "        }\n",
    "        \n",
    "        # Plot actual values\n",
    "        actual = y_test_data[horizon]\n",
    "        ax.plot(actual, label='Actual', linewidth=2.5, color='#333333', alpha=0.7, zorder=5, linestyle='-')\n",
    "        \n",
    "        # Plot model predictions\n",
    "        for model_name, preds in sorted(horizon_data.items()):\n",
    "            color = model_colors.get(model_name, '#999999')\n",
    "            ax.plot(preds, label=model_name, alpha=0.85, linewidth=2, color=color, linestyle='--')\n",
    "        \n",
    "        # Zooming\n",
    "        all_series = [actual] + list(horizon_data.values())\n",
    "        y_min = min(np.min(s) for s in all_series)\n",
    "        y_max = max(np.max(s) for s in all_series)\n",
    "        y_range = y_max - y_min\n",
    "        y_padding = zoom_factor * y_range\n",
    "        ax.set_ylim(y_min - y_padding, y_max + y_padding)\n",
    "        \n",
    "        ax.set_xlim(-50, len(actual) + 50)\n",
    "        \n",
    "        ax.set_title(f'Horizon {horizon} days ahead - Model Comparison (Zoomed)', fontsize=16, fontweight='bold', pad=20)\n",
    "        ax.set_xlabel('Time Steps', fontsize=13)\n",
    "        ax.set_ylabel('Mean Real Estate Price', fontsize=13)\n",
    "        ax.legend(loc='best', fontsize=12, framealpha=0.95, shadow=True, fancybox=True)\n",
    "        ax.grid(True, alpha=0.4, linestyle='--', linewidth=0.8)\n",
    "        ax.set_facecolor('#f8f9fa')\n",
    "        ax.minorticks_on()\n",
    "        ax.grid(which='minor', alpha=0.2, linestyle=':', linewidth=0.5)\n",
    "        ax.yaxis.set_major_formatter(plt.FormatStrFormatter('%.2f'))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def plot_residuals(all_horizon_data, y_test_data):\n",
    "    horizons = sorted(all_horizon_data.keys())\n",
    "    \n",
    "    for horizon in horizons:\n",
    "        horizon_data = all_horizon_data[horizon]\n",
    "        actual = y_test_data[horizon]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(16, 6))\n",
    "        \n",
    "        model_colors = {\n",
    "            'GradientBoosting': '#1f77b4',\n",
    "            'LightGBM': '#ff7f0e',\n",
    "            'CatBoost': '#2ca02c',\n",
    "            'AdaBoost': '#d62728',\n",
    "            'XGBoost': '#9467bd'\n",
    "        }\n",
    "        \n",
    "        for model_name, preds in sorted(horizon_data.items()):\n",
    "            residuals = preds - actual\n",
    "            color = model_colors.get(model_name, '#999999')\n",
    "            ax.plot(residuals, label=model_name, alpha=0.8, linewidth=1.5, color=color)\n",
    "        \n",
    "        ax.axhline(y=0, color='black', linestyle='-', linewidth=2, alpha=0.3, label='Zero Error')\n",
    "        \n",
    "        ax.set_title(f'Horizon {horizon} - Prediction Residuals (Prediction - Actual)', fontsize=16, fontweight='bold', pad=20)\n",
    "        ax.set_xlabel('Time Steps', fontsize=13)\n",
    "        ax.set_ylabel('Residual (Prediction Error)', fontsize=13)\n",
    "        ax.legend(loc='best', fontsize=11, framealpha=0.95)\n",
    "        ax.grid(True, alpha=0.4, linestyle='--')\n",
    "        ax.set_facecolor('#f8f9fa')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def plot_focused_window(all_horizon_data, y_test_data, start_idx=0, window_size=500):\n",
    "    horizons = sorted(all_horizon_data.keys())\n",
    "    \n",
    "    for horizon in horizons:\n",
    "        horizon_data = all_horizon_data[horizon]\n",
    "        actual = y_test_data[horizon]\n",
    "        \n",
    "        end_idx = min(start_idx + window_size, len(actual))\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(32, 20))\n",
    "        \n",
    "        model_colors = {\n",
    "            'GradientBoosting': '#1f77b4',\n",
    "            'LightGBM': '#ff7f0e',\n",
    "            'CatBoost': '#2ca02c',\n",
    "            'AdaBoost': '#d62728',\n",
    "            'XGBoost': '#9467bd'\n",
    "        }\n",
    "        \n",
    "        x_range = range(start_idx, end_idx)\n",
    "        ax.plot(x_range, actual[start_idx:end_idx], label='Actual', linewidth=2, color='#333333', alpha=0.5, linestyle='--')\n",
    "        \n",
    "        for model_name, preds in sorted(horizon_data.items()):\n",
    "            color = model_colors.get(model_name, '#999999')\n",
    "            ax.plot(x_range, preds[start_idx:end_idx], label=model_name, alpha=0.9, linewidth=2.5, color=color)\n",
    "        \n",
    "        ax.set_title(f'Horizon {horizon} - Time Steps {start_idx} to {end_idx} (Extreme Zoom)', fontsize=16, fontweight='bold', pad=20)\n",
    "        ax.set_xlabel('Time Steps', fontsize=13)\n",
    "        ax.set_ylabel('Mean Real Estate Price', fontsize=13)\n",
    "        ax.legend(loc='best', fontsize=12, framealpha=0.95)\n",
    "        ax.grid(True, alpha=0.5, linestyle='--')\n",
    "        ax.minorticks_on()\n",
    "        ax.grid(which='minor', alpha=0.25, linestyle=':')\n",
    "        ax.set_facecolor('#f8f9fa')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_combined_horizons_zoomed(all_horizon_data, y_test_all_horizons, zoom_factor=0.005)\n",
    "\n",
    "# To see residuals\n",
    "# plot_residuals(all_horizon_data, y_test_all_horizons)\n",
    "\n",
    "# To see a specific time window with extreme detail\n",
    "# plot_focused_window(all_horizon_data, y_test_all_horizons, start_idx=500, window_size=3000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucl_stock_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
